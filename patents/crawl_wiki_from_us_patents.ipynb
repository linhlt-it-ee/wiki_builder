{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "371f566f-f09c-443c-a806-39dddde4cf48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nonplanar', 'amorphous']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from utils import text_util, file_util, excel_tree_level_export\n",
    "from utils import graph_builder_from_wiki as graph_wiki_util\n",
    "import crawl_wiki_tree\n",
    "import extract_name_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "056338ae-e790-4381-920b-7cb4e79dd8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data/google_patents/us-25000\"\n",
    "DOC_DIR = os.path.join(DATA_DIR, \"doc\")\n",
    "max_level = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9be2bb-602f-4087-be17-1268a604955b",
   "metadata": {},
   "source": [
    "Format of data file:\n",
    "- A `.json` file contains multiple patents on different lines.\n",
    "- Format of each patent:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"patent_id\": str,\n",
    "    \"title\": [{\"text\": str, \"language\": str, \"truncated\": bool}],\n",
    "    \"description\": [{\"text\": str, \"language\": str, \"truncated\": bool}],\n",
    "    \"claims\": [{\"text\": str, \"language\": str, \"truncated\": bool}],\n",
    "    \"classifications\": [{\"code\": str, \"inventive\": bool, \"first\": bool, \"tree\": List[str]}, ...]\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b091803b-a5b0-4993-9053-ffe8eceb6ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of document files: 10\n"
     ]
    }
   ],
   "source": [
    "doc_files = file_util.get_file_name_in_dir(DOC_DIR, \"json\")\n",
    "print(\"Number of document files:\", len(doc_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57a5bd43-7499-4dcd-acc2-0a6135415c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_doc_file = doc_files[0]\n",
    "with open(sample_doc_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        sample_doc = json.loads(line)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1be04f0b-a179-4ce3-bb3c-8413cabc57f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'code': 'A46B11/0006', 'inventive': True, 'first': True, 'tree': []},\n",
       " {'code': 'A46B9/023', 'inventive': True, 'first': False, 'tree': []},\n",
       " {'code': 'A45D24/28', 'inventive': True, 'first': False, 'tree': []},\n",
       " {'code': 'A46B5/0095', 'inventive': True, 'first': False, 'tree': []},\n",
       " {'code': 'A45D24/22', 'inventive': False, 'first': False, 'tree': []},\n",
       " {'code': 'A46B11/002', 'inventive': True, 'first': False, 'tree': []},\n",
       " {'code': 'A46B2200/104', 'inventive': False, 'first': False, 'tree': []},\n",
       " {'code': 'A46B9/023', 'inventive': True, 'first': False, 'tree': []},\n",
       " {'code': 'A46B2200/104', 'inventive': False, 'first': False, 'tree': []},\n",
       " {'code': 'A45D24/22', 'inventive': False, 'first': False, 'tree': []},\n",
       " {'code': 'A46B11/0006', 'inventive': True, 'first': True, 'tree': []},\n",
       " {'code': 'A46B5/0095', 'inventive': True, 'first': False, 'tree': []},\n",
       " {'code': 'A46B11/002', 'inventive': False, 'first': False, 'tree': []}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_doc[\"classifications\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05aeb8a0-e9b1-4325-a075-d9eecd1d8edb",
   "metadata": {},
   "source": [
    "## Extract name mentions from each document\n",
    "\n",
    "For later reference, save name mentions in each document with `doc_id` into a folder named `name_mention_<doc_id>.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a721d055-67ef-486b-bd4b-3de31b5d3fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(doc):\n",
    "    return doc[\"patent_id\"]\n",
    "\n",
    "def get_claims(doc):\n",
    "    return [c[\"text\"] for c in doc[\"claims\"]]\n",
    "    \n",
    "def get_name_mentions(doc, max_n_gram_range=3):\n",
    "    claims = get_claims(doc)\n",
    "    name_mentions = text_util.get_name_mention_from_claims_nltk(claims)\n",
    "    n_gram_name_mentions = text_util.generate_n_gram_from_name_mentions(name_mentions, max_n_gram_range)\n",
    "    return n_gram_name_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53c056d9-4705-4aee-94c7-92df4f5d36e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name mentions: ['wall', 'bristles', 'boot', 'medial section', 'fluid', 'secondary end', 'distal end', 'relative', 'outer', 'straight end section', 'handle', 'medial', 'communication', 'bristle', 'straight end', 'conduit', 'pump', 'undulated medial section', 'openings', 'adjacent', 'straight', 'boots', 'fluid communication', 'weight retains', 'hair', 'retains', 'outer surface', 'brush', 'surface', 'end', 'outer wall', 'undulated', 'tube', 'leading', 'weight', 'section', 'plurality', 'panel', 'primary end', 'claim', 'distal', 'respect', 'primary', 'leading end', 'end section', 'assembly', 'undulated medial', 'secondary']\n"
     ]
    }
   ],
   "source": [
    "name_mentions = get_name_mentions(sample_doc)\n",
    "print(\"Name mentions:\", name_mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b52c69-9741-4d1e-9f34-e6d6287a9889",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME_MENTION_DIR = os.path.join(DATA_DIR, \"name_mentions\")\n",
    "num_name_mentions_file = 50\n",
    "\n",
    "all_name_mentions = set()\n",
    "dict_name_mentions = {}\n",
    "\n",
    "if not os.path.exists(NAME_MENTION_DIR):\n",
    "    file_util.mkdir(NAME_MENTION_DIR)\n",
    "    for file_name in tqdm(doc_files, desc=\"Extracting name mentions\"):\n",
    "        with open(file_name, \"r\") as f:\n",
    "            for line in f:\n",
    "                doc = json.loads(line)\n",
    "                doc_id, name_mentions = get_id(doc), get_name_mentions(doc)\n",
    "                dict_name_mentions[doc_id] = name_mentions\n",
    "                all_name_mentions.update(name_mentions)\n",
    "    \n",
    "    \n",
    "    file_util.dump_json(dict_name_mentions, os.path.join(DATA_DIR, \"dict_name_mentions.json\"))\n",
    "    all_name_mentions = list(all_name_mentions)\n",
    "    print(\"Number of name mentions to crawl:\", len(all_name_mentions))\n",
    "    extract_name_mentions.split_name_mention_list(all_name_mentions, NAME_MENTION_DIR, num_name_mentions_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f3d4dc-86ec-4a94-89a1-49c8ac6d54fc",
   "metadata": {},
   "source": [
    "## Retrieve parents of name mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbe7abd-449c-4b2a-8c5f-6bfa70558b6d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "crawl_wiki_tree.search_wiki_with_threads(NAME_MENTION_DIR, 0, num_name_mentions_file, iteration=max_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ccb643-4318-4a78-b98a-825d05d12838",
   "metadata": {},
   "source": [
    "## Trace paths of parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4878e211-b9fe-48e7-ab04-6c30279dfdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def cache_linkto(parent_links):\n",
    "    linkto_infos = {}\n",
    "    for link in parent_links:\n",
    "        src_id, src_label, dest_id = link[\"id\"], link[\"label\"], link[\"link_to\"]\n",
    "        if src_id not in linkto_infos:\n",
    "            linkto_infos[src_id] = {\"label\": src_label, \"link_to\": set()}\n",
    "        if dest_id != \"\":\n",
    "            linkto_infos[src_id][\"link_to\"].add(dest_id)\n",
    "\n",
    "    for src_id in linkto_infos:\n",
    "        linkto_infos[src_id][\"link_to\"] = list(linkto_infos[src_id][\"link_to\"])\n",
    "    \n",
    "    return linkto_infos\n",
    "\n",
    "\n",
    "def trace_path(root_id, entity, max_level):\n",
    "    linkto_infos = cache_linkto(entity[\"parents\"])\n",
    "    labels = {root_id: entity[\"label\"]}\n",
    "    parents = []\n",
    "    \n",
    "    # BFS to get parent up to max_level\n",
    "    queue = deque()\n",
    "    queue.append(root_id)\n",
    "    level = {root_id : 0}\n",
    "    path = {root_id: str(root_id)}\n",
    "    \n",
    "    while len(queue) != 0:\n",
    "        u = queue.popleft()\n",
    "        for v in linkto_infos[u][\"link_to\"]:\n",
    "            if v not in level and v in linkto_infos:\n",
    "                level[v] = level[u] + 1\n",
    "                path[v] = \"{} >> {}\".format(path[u], v)\n",
    "                labels[v] = linkto_infos[v][\"label\"]\n",
    "                parents.append({\n",
    "                    \"id\": v, \n",
    "                    \"level\": level[v], \n",
    "                    \"label\": labels[v],\n",
    "                    \"path\": path[v],\n",
    "                })\n",
    "                if level[v] < max_level:\n",
    "                    queue.append(v)\n",
    "    \n",
    "    return parents, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33ca4324-b84f-4d63-8873-d1472fd87cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_entity_file = file_util.get_file_name_in_dir_regex(NAME_MENTION_DIR, \"entities.pck\")[5]\n",
    "sample_entity = file_util.load(sample_entity_file)\n",
    "sample_entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee20f58-5f42-4723-9355-d89ee7ec1a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name_mention_eid, entity in sample_entity.items():\n",
    "    try:\n",
    "        print(trace_path(name_mention_eid, entity, max_level=max_level))\n",
    "    except KeyError:\n",
    "        print(\"TRACING ERROR\", name_mention_eid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d911baa1-82e0-4ed2-a930-fc73a6e320c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tracing parents:   0%|          | 0/10788 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "ENTITY_LABEL_PATH = os.path.join(DATA_DIR, \"entity_labels.json\")\n",
    "\n",
    "file_names = file_util.get_file_name_in_dir(NAME_MENTION_DIR, \"txt\")\n",
    "entity_labels = {}\n",
    "\n",
    "for file_name in tqdm(file_names, desc=\"Tracing parents\"):\n",
    "    base_name = os.path.splitext(file_name)[0]\n",
    "    entity_path = base_name + \"_entities.pck\"\n",
    "    parent_path = base_name + \"_parents.json\"\n",
    "    error_path = base_name + \"_entities_cannot_trace_parents.json\"\n",
    "    \n",
    "    file_entity = file_util.load(entity_path)\n",
    "    entity_parents = {}\n",
    "    errors = []\n",
    "    \n",
    "    for name_mention_eid, entity in file_entity.items():\n",
    "        try:\n",
    "            parents, labels = trace_path(name_mention_eid, entity, max_level=max_level)\n",
    "        except KeyError:\n",
    "            errors.append(file_entity[name_mention_eid])\n",
    "            continue\n",
    "        entity_parents[name_mention_eid] = {\"name_mention\": entity[\"name_mention\"], \"label\": entity[\"label\"], \"parents\": parents}\n",
    "        entity_labels.update(labels)\n",
    "        \n",
    "    file_util.dump_json(entity_labels, ENTITY_LABEL_PATH)\n",
    "    file_util.dump_json(entity_parents, parent_path)\n",
    "    file_util.dump_json(errors, error_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
